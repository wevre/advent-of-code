:project Advent of code 2021
   :created 2021-12-10
   :author Mike Weaver

:section Introduction
   These are my notes and thoughts on the AoC puzzles of 2021.

:section To Do's

   [] Redo Day-2 with using reduce (instead of loop-recur) and a function that
   switches on a condition based on the command. Also, a re-seq looking for \w+
   and \d+ can then be mapped into keyword and parseInt quite simply.

   [] Day_4 I had an idea to process each bingo card and return back how many
   turns before it won. That would have been a solution I could have used for
   both parts, maybe go back and redo it that way.

   [] Create a test subfolder and test source files and some of the comments in
   the code can be moved into test files.

   [] I think I can also make some 'alt' branches where I can stash alternate
   approaches.

:section Day 8

   I modified my original solution (which used some rules to determine
   particular digits after the "unique" digits were solved) to use a
   "fingerprint" approach that I saw described in some random youtube video.

   Idea is to create a 'fingerprint' for each segment, which is the count of
   segments in each digit where the segment appears. For example, segment 'a' is
   in the digits (0 2 3 5 6 7 8 9), and those digits have segment counts of (6 5
   5 5 6 3 7 6), respectively. Sorted, those are (3 5 5 5 6 6 6 7), which is a
   unique fingerprint for segment 'a', or, on the scambled input, for the
   segment which _should_ be 'a'. The other segments 'b' through 'g' likewise
   have unique fingerprints. We fingerprint the randomized input and use it to
   identify the correct segment and ultimately the output digits.

:section Day 15

   Three pieces to this solution, which is an implementation of Dijkstra's
   algorithm:

      1. a 1-dim vector of the input data, `risks`, and the function
      `risk<-loc` that returns the risk for a given 'location' (where a
      'location' is a vector of `[row, col]` and basically lets us treat
      `risks` as if it were a 2-dim matrix);

      2. a set of `visited` locations; and,

      3. a priority-map, `distances`, whose keys are `[r c]` locations and whose
      values are tentative distances. Because `distances` is a priority-map, it
      stays sorted by tentative distance, so after we remove the current node
      from `distances` and add it to `visited` then the next current node is
      simply `(first distances)`.

   Three other implementation notes:

      1. I did not load up `distances` with every location initialized to ##Inf
      as per the standard Dijkstra algorithm. They are instead initialized
      on-the-fly by the `update-distance` function.

      2. For part 2 I did not expand `risks` to be 25 times as big. Instead the
      `risk<-loc` function projects larger coordinates back onto the original
      vector, adjusting the original risk level correspondingly.

      3. I switch from part 1 to part 2 by redefining the var `scale` using
      `with-redefs`.

         :NOTE This `with-redefs` is really cool and probably I'll use it more
         with my code to test sample puzzles. It's kind of a cheaty way to run
         sample problems without having to pass all the config parameters
         through each function. Go ahead and let those configs be namespaced
         def's (I know, globals are considered harmful, but not for simple
         programs like these AoC puzzles) knowing you can temporarily override
         them to run a check on sample inputs.

:section Day 16

   I chose not to have a global atom to help consume the bits. Instead, all my
   parse functions take bits and return a vector `[result bits]`. Consistently,
   then, all calls to these functions destructure the results with this pattern:
      ```
         (defn parse-zzz [bits]
           (let [[result bits] (parse-xxx bits)
                [other bits] (parse-yyy bits)]
             ...do something...
             [result bits])
   I normally don't like clobbering vars with repeating let bindings, but here
   the pattern is useful and consistent. To evaluate the results, I use
   clojure.walk/postwalk which is one of those 'magical' functions that I love
   to use. And first time for me, I used clojure.core.match/match to identify
   the particular subforms (during the walk) that need to be evaluated.

:section Day 17

   Puzzle 1 was done 'by hand' with a calculator and Excel and some knowledge of
   triangle numbers. I confirmed with Excel that for my input, the x-velocity
   could be no lower than 17 otherwise drag would prevent the probe from ever
   reaching the target area. (I made a rough guess by taking the target mid-x,
   doubling, and then taking the square root, and that rough estimate got me
   pretty close.) Obviously the x-velocity has an upper bound of target-max-x.
   In my code, however, I don't bother with the minimum x-velocity because it's
   only a few extra loops to check, and then my code can be run on the sample
   problem with fewer modifications.

   For the y-velocity, we shoot the probe up and when it comes back to y=0, it
   will have negative of it's initial velocity, and then the next y-point it
   hits will be (inc (neg init-y-vel)). So, for example with my input, the
   biggest y-velocity we can choose is 114-1=113. And -114 is the lowest
   y-velocity allowed (continuing with my particular puzzle input) because
   otherwise we completely overshoot the target on the very first step.

   The above logic gives a simple range to test: 0 <= x <= target-max-x and
   target-min-y <= y <= -target-min-y. You could shave a few milliseconds by
   tightening the lower bound for x, but why bother?

:section Day 18

   Zippers! We can query a zipper location for its `path` to see how deep it is
   nested, and the `prev` and `next` functions can find left and right
   neighbors.

   I read the instructions incorrectly and first wrote logic to find the first
   node that was either explodable or splitable and do that. But the
   instructions say otherwise, although I think they could have been clearer:

      1. START

      2. If there are _any_ explodable nodes anywhere in the number, explode the
      left-most and start over.

      3. Else, if there are _any_ splitable nodes, explode the left-most and
      start over.

   Thought: does exploding ever _increase_ the depth of the nodes it touches? I
   don't think it does. So maybe you could change the second step above to "If
   there are any explodable nodes do them all and start over." But I have a
   general function `apply-one-action` that I can use to do a single explode or
   split, and if I changed my logic to do all explosions together, I wouldn't be
   able to use that function.

   I feel like I pulled out all the big guns this time: edn/read-string (which
   did all the work of parsing the input--hooray that commas are whitespace in
   clojure!), zippers, and postwalk.

   My original `reduce-sfn` was ungainly, it was basically the initial tip of a
   pyramid of doom. I liked zelark's approach which used `condp` which I'm not
   as familiar with, so I refactored mine to also use `condp`.

:section Day 20

   The `parse-input` function is unusually large, because I made the decision to
   keep track of min/max x and y (actually, rows and cols) while parsing the
   input. Later I expand those extrema at each step of the image enhancement.

   In the sample data, index 0 of the algorithm is (.), so all the dark pixels
   outside the image stay dark at each step. But in the puzzle data, index 0 is
   (#) so the surround toggles between light and dark. I didn't try and simulate
   that (how? by including extra cells around the actual puzzle, expanding and
   toggling those at each step? You would still need to have a 'default' pixel
   for anything beyond what you were modeling.) I just had a default
   'background' value and an associated function to toggle it between 0 and 1.
   For the sample puzzle I redefined the toggle function to be `identity`.

   I guess what I'm trying to get to in the above paragraph is you have to
   'know' something about the input data in order to run the solution correctly.
   I could, I suppose, have written some logic to check the first and last index
   of the algorithm to determine whether it toggled or not, but I didn't do
   that, you just have to manually look and then choose the correct `toggle`
   function. I'm okay doing that with a redef.

:section Day 21

   At any point, there are 21 ways (universes, I suppose) that the next player
   could roll the dice, but there are only 7 sums of those three dice. You could
   only worry about those seven paths, and multiply the outcomes by the
   probability, but you can also just use memoization, which I think will also
   come in handy with the positions, which cycle around and repeat. I wonder is
   there a way with memoization to see how often the same combination of
   parameters is hit? I suppose, there are (1..10) x (1..10) x (0..29) x
   (0..29) combinations of parameters: 90,000 combinations. That seems like a
   lot, but the number of universes is over 1.25 quadrillion (1.25e15), so yeah,
   the same combinations must repeat a few times or so.

:section Day 24

   The big hint here is the warning "You'll need to figure out what MONAD does
   some other way". So, looking at the instructions, there are 14 sets of nearly
   identical commands, which look like this:

   ```
         inp w    ;; w = dig
         mul x 0  ;;
         add x z  ;; x = z
         mod x 26 ;; x = z%26
         div z A  ;; z = z / A          <-- PARAM A
         add x B ;; x = z%26+B          <-- PARAM B
         eql x w  ;; if dig == z%26+B then x = 1 else x = 0
         eql x 0  ;; if dig == z%26+B then x = 0 else x = 1
         mul y 0  ;;
         add y 25 ;; y = 25
         mul y x  ;; if dig == z%26+B then y = 0 else y = 25
         add y 1  ;; if dig == z%26+B then y = 1 else y = 26
         mul z y  ;; if dig == z%26+B then z = z/A else z = z/A * 26
         mul y 0  ;;
         add y w  ;; y = dig
         add y C  ;; y = dig + C        <-- PARAM C
         mul y x  ;; if dig == z%26+B then y = 0 else y = dig + C
         add z y  ;; if dig == z%26+B then z = z/A else z = z/A*26 + dig + C

   The unique parameters are on lines 5, 6, and 16 of each set. The result of
   all this is this formula:

      if dig == z%26 + B then z = z/A else z = z/A*26 + dig + C

   There are 7 sets where B is small enough (including some sets where it is
   negative) that you can get the right digit to hit the 'divide' branch of that
   'if'. If you are getting those divides, then the first digit ends up (after
   the even number of multiplications and divisions) affecting the final digit.
   Or, rather, the C parameter of the first set and the B parameter of the last
   set determine together the valid ranges for the first digit. I worked this
   all out in a spreadsheet to figure out what was going on, and ended up just
   solving it right there in Excel.
