:project Advent of Code 2022
   :created 2022-12-01
   :author Mike Weaver

:section Day 01

   My son Isaac was watching me as I hurried to try and do the puzzles before
   taking him to school. He was more interested in the "story" for 2023. Puzzle
   1 was really quick and I was showing him the story and the code and hadn't
   scrolled down yet to see what puzzle 2 was about, but I (correctly) predicted
   to him that it would probably involve parsing the "one" "two" etc that we
   were seeing in the sample input.

   I _did_ notice that some of the words overlapped, but at first I didn't
   consider that valid: I thought "eightwo" should be parsed as "eight" "wo" and
   become only 8. Running my code on the sample data taught me that wasn't
   correct. Then I forgot that, for capture groups, re-seq returns a _vector_ of
   the matches. Unfortunately, because I was 'str'-ingifying values in the
   middle of the transormation chain, my code still sort of worked (in the sense
   that it didn't throw an exception) but just returned wrong values, so it took
   a while to realize.

   Another way to do this, after reading some of the comments on Clojurians
   slack, is to just find the first match of "1|one|2|two..." and the _last_
   match "1|eno|2|owt|..." and then keep just those. This doesn't care about
   overlaps because you just need the first/outermost match.

:section Day 02

   Was it just me or was this much easier than Day 01? I read the problem and
   thought: I only need to know the maximum number of each color pulled out of
   the bag. I don't really need to know (or at least, hopefully when puzzle 2 is
   revealed, I won't need to know) how many sets were drawn for each game, or if
   a set only had one color or any of those details like that. So I didn't model
   sets when I parsed, I just read in a stream of digits and colors, partitioned
   them into groups of two, and reduced them into a map keeping track of the max
   number of cubes seen for each color.

   It was a good gamble, because puzzle 2 also relied only on those max values.

   I did do one refactor for puzzle 2, however. My original keep-only-max map
   was keyed by strings. But when I got to puzzle 2, I wanted to destructure my
   map keys, and ... wait. I can destructure string keys! I forgot. I thought I
   had to turn my colors from strings into keywords so I could destructure them,
   but no, I can destructure string keys. Wow! I forgot about that. I'm going to
   go change that right now.

   So, that's done. As I was saying above, I refactored my keys from strings
   into keywords when I got to puzzle 2. But now I've done a second refactor
   that cancels that out and I'm back to strings as keys, so and I guess I can
   say that net of all these tweaks, I didn't have to change my approach for the
   second puzzle (even though for a brief moment I did---we'll just say that was
   explorative programming, or research, or "art").

:section Day 03

   I have the luxury (on weekends, at least) to be awake at 10pm when the
   puzzles come out, so I can sometimes do them right away. I came up with a
   solution for Day 03 using my already-built `locmap<-` function, which was
   "easy" (and yes, that's a loaded term in the Clojureverse), because it gives
   me a map of positions to characters. But the rest of my solution, especially
   stitching together the part numbers, was convoluted---everything forced to
   deal with the fact that I had (blindly) parsed _first_ and then had to go
   back _after_ to make sense of it all. I submitted my answer and went to bed,
   but I was already thinking of a different approach based on doing my own
   custom parsing and gathering important stuff (like the part numbers) along
   the way.

   I woke up and had a busy morning but was finally able to go try out
   implementing the idea I'd coded in my head last night instead of falling
   asleep. I know others probably did something similar to this approach, but
   the only one I've looked at so far is @zelark's. He parsed each line and made
   good use of the `.start` and `.end` methods in `java.util.regex.Matcher`
   (TIL). Brilliant. I kept to my original idea of parsing the whole thing as a
   stream of characters, treating \newline as just one more character to deal
   with.

   I like this v2 solution. It's shorter, but I also think it is easier to grok,
   which makes sense because I'm not forcing myself into a corner with my
   `locmap<-` function. Don't worry, `locmap<-`, I'm sure there's a GameOfLife
   kind of puzzle coming up and you'll be called into duty.

:section Day 04

   I chose not so stay up later on Sunday night to work on this, so just tackled
   it in the morning, in between waking up kids and getting lunches ready. Part
   1 was very easy. For part 2, I did a straightforward solution probably
   similar to everyone else. I had a hunch there was some more 'mathmatical' way
   to do it rather than just incrementing buckets, but I didn't want to try and
   figure it out.

   After I posted and started reading through the Clojurians slack, Sam Ferrell
   had implemented that other way. As @genmeblog aptly stated, it's the
   difference between reverse processing and forward processing. I created a v2
   to try out Sam's approach and, because I was curious, to test out execution
   times. This data probably isn't large enough to really tell, but the reverse
   approach appears to be slightly faster. And, bonus, you don't have to keep
   track of card numbers.

:section Day 05

   We got home late from a party so I decided to stay up and tackle day 05
   instead of (what I should have done) going to bed. The first part was easy
   and I should have guessed at what would be coming up in part 2. Even though I
   knew it wouldn't work, I tried the brute force approach of sending nearly 2
   billion seed values through the chain of maps like I'd done for part 1. Of
   course that would take way to long, so then I knew I had to deal with
   sub-dividing ranges. I haven't gone back to go find it, but it seems like
   there was a 3-D version of this same type of problem in a previous year.

   I had used `reduced` in my 1-D solution, so when I adapted all the code over
   to 2-D I kept that in there. Once I successfully mapped a sub-range from src
   to dst, I marked it as reduced and skipped it in later sweeps. I guess the
   other way to approach that is to keep two lists, one for ranges that haven't
   been mapped yet, and one for those that have. I just kept one list but
   started marking converted ranges with reduced.

   I wanted to do some refactoring on my parsing logic, since I had two or three
   steps of input parsing logic repeated for both puzzles, but I went to bed
   instead. When I got up this morning, I did that refactoring and I also went
   back and cleaned up by break-up-a-range-into-sub-ranges logic a little bit.
   It's still the same logic and approach, but I think this version is a little
   easier (maybe?) to understand what is going on. Instead dealing with each of
   the six overlap/subrange cases (where there is some repeated logic among
   the six cases), I boiled that down to generating three (possibly invalid)
   sub-ranges, and drop any that have negative lengths.

:section Day 06

   I solved this with pen and paper. It's just the quadratic formula.

:section Day 07

   I did a 'signature' approach. The frequencies of the cards map directly to
   the hand type. For example, if (vals (frequencies)) is (1 1 1 1 1) then you
   have a :high-card type for the hand. I actually did the `count` of the
   frequencies as my signature (to avoid having to sort the vals):

   |||
      cnt | type
      5   | :high-card
      4   | :one-pair
      3   | either :three (3 1 1) or :two-pair (2 2 1)
      2   | either :four (4 1) or :house (3 2)
      1   | :five

   So I wrote a conditional based on the counts, and then for cases 3 and 2 I
   assigned hand type using a set of the vals.

   I converted from hand type to hand strength with a map and I chose values
   that sort of mimicked the hand type, which made my life easier when printing
   out examples and debugging.

   I also created a custom comparator because why not? I knew I could just put
   hand strength and cards in a vector and it would sort properly but I guess I
   was feeling adventurous.

   For part two I made new versions of things. My j-type<- function now checked
   for \J as a key in the frequencies map and altered the return type based on
   that. For the situation where the vals were [2 2 1] it depended on whether \J
   was two cards (which results in :four) or one card (which results in :house).
   Initially I thought "Oh, I'll combine the \J count with the largest and then
   re-determine the hand type" but that is extra work that is not needed. For
   all the situations except for [2 1 1] there is only one choice of alternative
   hand type when \J is present.

   I looked over my solution and I liked it. I thought: I could unify my two
   type<- functions, but whatever I'm submitting it. So I did.

   Then I went and perused the slack channel and my favorite idea to steal (from
   @genmeblog) was to remap the 'face cards' from AKQJT to EDCBA to make them
   'sort ready'. Based on that change I followed through with some stuff that I
   was too lazy in my first pass. So my changes in v2 were:

      1. Map 'face cards' to 'sortable' characters (removes the need to have two
      card-strength maps).
      2. Put strength and sortable in a vector that will sort properly (removes
      the need to have a custom comparator).
      3. Do all of that right in the parse-line function.
      4. Unify the two type<- functions. Now I just check for \1 and I know that
      I'm dealing with puzzle 2.

   One thing I didn't try was to use the sorted vals of the frequency map as the
   signatures. Doing so probably cleans up my nested `case`'s, but you
   still have to deal with the [2 2 1] situation and whether \J is one or two
   cards in the hand. Maybe I'll have some fun and do a v3.

   I did a version 3 and I like it best of all. I created a signature map, and
   for wild cards, I put a 0 in the signature. That gets rid of all my case
   statements, they are now encoded as data in the signature map.

:section Day 08

   I saw right away this was a LCM problem. There always seems to be at least
   one in each year's AoC. But as I was exploring the problem space, checking
   some divisions in the repl, I mistakenly typed the length of the instructions
   as 203 instead of 293 and that led me to some wrong conclusions and I got
   stuck thinking this was a Chinese Remainder Theorem type of problem. The
   result of that was I kept getting an answer to puzzle 2 that was too small.

   I went back and re-wrote my `find-steps` program to do multiple cycles,
   instead of stopping at the first "**Z" node. That confirmed that everything
   loops around regularly and also that my detour into CRT was incorrect.

   This is almost a "do it in Excel" or "do it on paper" kind of problem. I only
   wrote one function to parse the input, and one function to find the cycles
   and the rest is all in rich comments, documenting how I explored and
   confirmed my hunches about the inputs.

:section Day 09

   We had a fun ski day, then went straight to a piano recital, and the kids
   wanted to eat something and we finally got home right before AoC opened up.
   And, wow, this was probably the easiest day so far. How come this wasn't day
   1? Maybe it didn't fit well into the storyline. Who knows?

   I wrote both a post-predict and a pre-predict function, where one added last
   values, and the other subtracted first values, and then I had a thought that
   maybe the same predict function on the _reversed_ sequence would give us the
   backwards-extrapolated values. It was easy to check and it worked!, so I
   ditched the pre-predict function and just reversed the input for part 2.

:section Day 10

   I made a map (called next<-) that takes a pipe type (pype?) and the move
   _into_ the pipe (for example [0 -1] means we decremented the column, i.e.
   moved left into the new pipe) and returns the move _out_ of the pipe. For
   example, moving into a pype '7' from [0 1] (right) would move us out to [1 0]
   (down).

   From there I examined the input to find 'S', and looked at the input to see
   what pype replaced 'S' (for my input it was '-') and then did a fn/recur
   moving into and out of pypes until I was back at the starting loc. That to
   define the path.

   For the answer to part 2 I used the even-odd rule, but I had to be careful
   about what I counted as 'crossing' the path. If I was searching along the
   row, then a pattern like this: 'F--7' did not count as crossing the path. But
   a pattern like this: 'L--7' _did_ count as crossing the path. In the first
   instance, it's like the path came up to meet us, but then went back down
   again, so no crossing (it's more like a tangent, or a kiss); whereas in the
   second pattern, the path came down and then kept going down so it is a true
   crossing.

   I was going to be efficient in my rays and always go towards the nearest
   edge, but I didn't want to code up all the intricate crossings vs kisses, so
   I just searched 'up' for every cell.

   I thought about it afterwards and a more efficient approach, I think, would
   be to scan each row of the input, and count crossings by looking for L7 and
   FJ patterns (and of course, |) and incrementing each time we hit a cell
   'inside' the path (because our current crossing count would be odd). This
   would require only one pass over the data, instead of my less efficient
   algorithm (I think it is like O(x^3) because it re-traverses the same cells
   over and over again as it works its way down the map, but always searching
   upwards from every loc). I had that idea but I haven't implemented it (yet)
   as my free time is somewhat limited at the moment.

:section Day 11

   This wasn't too hard of a puzzle. My solution was pretty straightforward. I
   used a filter to examine the rows/cols between each pair of galaxies and
   determine if they were empty (using pre-generated sets of all the empty rows
   and cols.) @erdos used a sorted set, a collection I don't think I've ever
   used before, which is more efficient. @zelark had a nice idea to compare the
   rows/cols along the path to the galaxy coords themselves to determine
   empty-ness.

   I liked that idea of @zelark's because it means I only have to keep track of
   the galaxies instead of the "empty's" nor the size. I also thought about it
   and came up with this idea: a manhattan distance is easy to do, no loop
   required. But to find the empty's we still have to do a loop. Since we're
   already doing a loop anyway, just add either a 1 or an `expand` as we do the
   loop.

:section Day 17

   I tried to do this with a Dijkstra algorithm, but that won't work. I had to
   go educate myself on the differences between A-start and Dijkstra and got
   that sorted. I relied a lot on @zelark's code to realize what was going on.
   Then I had to do one more tweak: the "key" for each node had to be the
   location _plus_ the direction from which we arrived at that location. Without
   both of those, we drop too many nodes. The direction we arrive at a node
   determines which nodes we can further search, so it turns this from a 2-D to
   a 3-D search.

   My code is really slow. It takes 40-50 seconds to complete the search. I'm
   sure there are ways to speed it up. I'm not interested in taking the time to
   do that. It might be nice to understand what could be done, but I have other
   things to worry about this time of year.

   I did come up with one optimization which roughly halved the search time:
   instead of storing [loc dir] as our identifier for each node (this making
   the dir we reached part of the "key" as explained above); instead of that I
   stored [loc orient] where orient was :H for R and L, and :V to U and D. The
   idea is that approaching a node from up or down (left or right) is the same.
   In the sense that our subsequent search space is the same.

   So I wonder if I stop keeping track of the path will that speed things up?
   Or does that even matter? An alternate way to drack our path is to keep a map
   of to<-from and then walk that from whatever the final node ends up being.
